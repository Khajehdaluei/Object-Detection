{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3ec8b6",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;text-align:center\"><img src=\"https://mohammadkh.ir/github/logo.png\" alt=\"Mohammadkh.ir\" style=\"width: 250px;\"/></div>\n",
    "<h1><div style=\"direction:rtl;text-align:center\">Object Detection</div></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4da137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905cf864",
   "metadata": {},
   "source": [
    "# Create Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5607d48f",
   "metadata": {},
   "source": [
    "#### Load img and Preoroccess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8857b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_preprocess(address):\n",
    "    img = cv2.imread(address)\n",
    "    h, w = img.shape[:2]\n",
    "    # blob --> fun perproccess img\n",
    "    # swapRB -> R <-> B\n",
    "    preprocessed_image = cv2.dnn.blobFromImage(img, scalefactor= 1/255, size= (416, 416), \n",
    "                                               swapRB = True, crop = False)\n",
    "    return img, preprocessed_image, h, w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318e32c",
   "metadata": {},
   "source": [
    "#### Load Model & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e9c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_and_label(label_address, weights_address, config_address):\n",
    "    # 80 object detect yolo3\n",
    "    labels = open(label_address).read().strip().split(\"\\n\")\n",
    "    net = cv2.dnn.readNet(weights_address, config_address)\n",
    "    \n",
    "    return labels, net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd217b58",
   "metadata": {},
   "source": [
    "#### Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e091fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(pre_processed_image, net):\n",
    "    net.setInput(pre_processed_image)\n",
    "    output_layers = [\"yolo_82\", \"yolo_94\", \"yolo_106\"]\n",
    "    predictions = net.forward(output_layers)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265555a3",
   "metadata": {},
   "source": [
    "#### proccess OutPut Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "751539e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(predictions, w, h):\n",
    "    # output model 85 array columes --> 4 loc(x_center,y_center,w,h) + P0 (dec obg) + P (80 objects)\n",
    "    # loc out model % --> %*shpe = loc\n",
    "    \n",
    "    classIDs = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for layer in predictions:                 # all detect object (\"yolo_82\", \"yolo_94\", \"yolo_106\")\n",
    "        for detected_object in layer:         # 85 col\n",
    "            scores = detected_object[5:]      # P (80 object)\n",
    "            classID = np.argmax(scores)       # select P obj max\n",
    "            confidence = scores[classID]      # read Pmax\n",
    "            \n",
    "            # loc box\n",
    "            if confidence > 0.6:\n",
    "                box = detected_object[0:4]*np.array([w, h, w, h])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - width/2)\n",
    "                y = int(centerY - height/2)\n",
    "\n",
    "                # add to list parms\n",
    "                classIDs.append(classID)\n",
    "                confidences.append(float(confidence))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                \n",
    "    return classIDs, confidences, boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70134716",
   "metadata": {},
   "source": [
    "#### Show OutPut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "786934bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.uniform(0, 255, size= (80, 3))\n",
    "# print(colors)\n",
    "\n",
    "def show_results(img, classIDs, confidences, boxes, labels):\n",
    "    cv2.namedWindow(\"image\",cv2.WINDOW_NORMAL)\n",
    "    #cv2.resizeWindow('image', 600,600)\n",
    "    \n",
    "    #  NMSBoxes --->  select one box for multi box in area ---> get prm box\n",
    "    idxs = cv2.dnn.NMSBoxes(bboxes=boxes, scores=confidences, score_threshold=0.3, nms_threshold=0.5)\n",
    "\n",
    "    for i in idxs.flatten():\n",
    "        (x, y) = boxes[i][0], boxes[i][1]\n",
    "        (w, h) = boxes[i][2], boxes[i][3]\n",
    "\n",
    "        # draw rectangle obj\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), colors[i], 10)\n",
    "        \n",
    "        # show label and confidence\n",
    "        ## text write\n",
    "        text = \"{} :  {:.2f}\".format(labels[classIDs[i]], confidences[i])\n",
    "        ##  draw rectangle bg text\n",
    "        cv2.rectangle(img, (x, y+45), (x+200, y), colors[i], -1)\n",
    "        ## put text \n",
    "        cv2.putText(img, text, (x+10, y+30), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 255, 255), 2)\n",
    "        \n",
    "    cv2.imwrite(\"__data/image/pic_yolo_per.jpg\", img)\n",
    "    cv2.imshow(\"image\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8db09a0",
   "metadata": {},
   "source": [
    "# detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6113aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, pre_img, h, w = load_data_and_preprocess(r\"__data/image/dc.jpg\") \n",
    "# img, pre_img, h, w = load_data_and_preprocess(r\"__data/image/family.jpg\") \n",
    "\n",
    "labels, net = read_model_and_label(r\"__data/yolov3/coco.names\",\n",
    "                                   r\"__data/yolov3/yolov3.weights\",\n",
    "                                   r\"__data/yolov3/yolov3.cfg\")\n",
    "\n",
    "predictions = inference(pre_img, net)\n",
    "                                   \n",
    "classIDs, confidences, boxes = post_processing(predictions, w, h)\n",
    "                                   \n",
    "show_results(img, classIDs, confidences, boxes, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860432d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<div style=\"direction:rtl;text-align:left\"><strong>Object Detection</strong><br>MohammadReza <strong>Khajedaloi</strong><br><br>\n",
    "</div>\n",
    "<div style=\"direction:rtl;text-align:right\">\n",
    "<a href=\"http://mohammadkh.ir/\">WebSite</a> - <a href=\"https://github.com/khajedaloi/\">GitHub</a> - <a href=\"https://www.linkedin.com/in/mohammad-kh/\">Linkedin</a>\n",
    "</div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep_"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
